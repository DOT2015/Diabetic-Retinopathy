{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3521043,"sourceType":"datasetVersion","datasetId":2118574}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About Dataset\n\n<img src=\"https://th.bing.com/th/id/R.a672705de96542b9f120f7dabc9dbf9a?rik=iEzFJf%2blYr0Acw&riu=http%3a%2f%2fpediatricophthalmologypa.com%2fwp-content%2fuploads%2f2014%2f01%2fDiabetic-Retinopathy-Blindness.png&ehk=vb2qvyFjNGpv6VGQWbnvpiIgpGtoCRrrPZKkJ4DMNMc%3d&risl=&pid=ImgRaw&r=0\" alt=\"centered image\" image align =\"right\" class=\"sc-hTnXLe UAvdY\" \n     width = '500' \n     height ='1000'/>\n\n## Total Class Labels = 5\n\n## Total Images = 2750\n\n### 1. Healthy (Not DR) = 1000\n\n### 2. Mild DR = 370\n\n### 3. Moderate DR = 900\n\n### 4. Proliferative DR = 290\n\n### 5. Severe DR = 190\n\n### DR: Diabetic Retinopathy\n\n","metadata":{}},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"markdown","source":"# 1 Import libraries","metadata":{}},{"cell_type":"code","source":"!pip install -U imbalanced-learn\n\nimport os\nimport shutil\nimport pathlib\nimport PIL\nimport cv2\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport random\nimport itertools\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, Dense, Activation\nfrom tensorflow .keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom PIL import Image, UnidentifiedImageError\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n\n\nprint(\"All done\")","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:45:33.538679Z","iopub.execute_input":"2023-11-28T20:45:33.539562Z","iopub.status.idle":"2023-11-28T20:45:45.173639Z","shell.execute_reply.started":"2023-11-28T20:45:33.539525Z","shell.execute_reply":"2023-11-28T20:45:45.172322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Read Data","metadata":{}},{"cell_type":"markdown","source":"## A- convert files to lists","metadata":{}},{"cell_type":"code","source":"Path_data = '/kaggle/input/diabetic-retinopathy-dataset'\ndata = os.listdir(Path_data)\nHealthy = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Healthy')\nMild = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Mild DR')\nModerate = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Moderate DR')\nProliferate = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Proliferate DR')\nSevere = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Severe DR')","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:46:18.51098Z","iopub.execute_input":"2023-11-28T20:46:18.511411Z","iopub.status.idle":"2023-11-28T20:46:18.523049Z","shell.execute_reply.started":"2023-11-28T20:46:18.511366Z","shell.execute_reply":"2023-11-28T20:46:18.522167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"classes names :\", (data), \"\\n______________________________\\n\")\nprint(\"Number of classes :\", len(data), \"\\n______________________________\\n\")\nprint(\"Number of Healty images :\", len(Healthy), \"\\n______________________________\\n\")\nprint(\"Number of Mild images :\", len(Mild),  \"\\n______________________________\\n\")\nprint(\"Number of Moderate images :\", len(Moderate),  \"\\n______________________________\\n\")\nprint(\"Number of Proliferate images :\", len(Proliferate),  \"\\n______________________________\\n\")\nprint(\"Number of severe images :\", len(Severe),  \"\\n______________________________\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:46:20.82993Z","iopub.execute_input":"2023-11-28T20:46:20.830616Z","iopub.status.idle":"2023-11-28T20:46:20.837369Z","shell.execute_reply.started":"2023-11-28T20:46:20.830581Z","shell.execute_reply":"2023-11-28T20:46:20.836451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As noticed above: data  imbalanced","metadata":{}},{"cell_type":"markdown","source":"## B- Create a dataframe","metadata":{}},{"cell_type":"code","source":"# Get Paths\n\nPath_data = '/kaggle/input/diabetic-retinopathy-dataset'\n\n# Create two lists to store paths of images and their labels\n\nimgpaths = []\nlabels =[]\n\n\n# Convert directory to list\n\ndata = os.listdir(Path_data)\n\n# Get paths and Labels of classes and images in data \n\nfor i in data:\n    classpath = os.path.join(Path_data, i)\n    imglist = os.listdir(classpath)\n    \n    for img in imglist:\n        imgpath = os.path.join(classpath, img)\n        \n        imgpaths.append(imgpath)\n        labels.append(i)\n\n\n# Convert two lists of imgpaths and their labels into series\n\nPaths = pd.Series(imgpaths, name = 'Paths')\nLabels = pd.Series(labels, name = 'Labels')\n\n# Concatenate them in one Dataframe called Tr_data\n\nDf= pd.concat([Paths, Labels], axis = 1)\nDf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:46:23.358343Z","iopub.execute_input":"2023-11-28T20:46:23.359095Z","iopub.status.idle":"2023-11-28T20:46:23.387588Z","shell.execute_reply.started":"2023-11-28T20:46:23.359061Z","shell.execute_reply":"2023-11-28T20:46:23.386709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Diabetic retinopathy is a complication of diabetes and a leading cause of blindness. It occurs when diabetes damages the tiny blood vessels inside the retina, the light-sensitive tissue at the back of the eye. A healthy retina is necessary for good vision.\nIf you have diabetic retinopathy, at first you may notice no changes to your vision. But over time, diabetic retinopathy can get worse and cause vision loss. Diabetic retinopathy usually affects both eyes.\n\n### Diabetic Retinopathy has four stages:\n\n## Mild Nonproliferative Retinopathy\nAt this earliest stage, microaneurysms occur. They are small areas of balloon-like swelling in the retinaâ€™s tiny blood vessels.\n\n## Moderate Nonproliferative Retinopathy\nAs the disease progresses, some blood vessels that nourish the retina are blocked.\n\n## Severe Nonproliferative Retinopathy\nMany more blood vessels are blocked, depriving several areas of the retina with their blood supply. These areas of the retina send signals to the body to grow new blood vessels for nourishment.\n\n## Proliferative Retinopathy\nAt this advanced stage, the signals sent by the retina for nourishment trigger the growth of new blood vessels. These new blood vessels are abnormal and fragile. They grow along the retina and along the surface of the clear, vitreous gel that fills the inside of the eye.\n\nBy themselves, these blood vessels do not cause symptoms or vision loss. However, they have thin, fragile walls. If they leak blood, severe vision loss and even blindness can result.\n\nref: https://petroueyecare.com/services/medical-eye-exams/diabetic-retinopathy/\n\n","metadata":{}},{"cell_type":"markdown","source":"# 3 Data Preptocessing","metadata":{}},{"cell_type":"markdown","source":"### Oversampling techniques for classification problems\n\n#### 1 Random oversampling\nRandom Oversampling involves supplementing the training data with multiple copies of some of the minority classes. Oversampling can be done more than once (2x, 3x, 5x, 10x, etc.) This is one of the earliest proposed methods, that is also proven to be robust.[3] Instead of duplicating every sample in the minority class, some of them may be randomly chosen with replacement.\n\n#### 2 Augmentation\nData augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.[8] (See: Data augmentation)\n\nref: https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#Oversampling_techniques_for_classification_problems","metadata":{}},{"cell_type":"markdown","source":"## A- Random Over sampling","metadata":{}},{"cell_type":"markdown","source":"more preferred with text data not with images","metadata":{}},{"cell_type":"code","source":"#X= Df.drop(['Labels'], axis = 1)\n#y = Df['Labels']\n#y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:37:35.934472Z","iopub.execute_input":"2023-11-28T18:37:35.934867Z","iopub.status.idle":"2023-11-28T18:37:35.945384Z","shell.execute_reply.started":"2023-11-28T18:37:35.934824Z","shell.execute_reply":"2023-11-28T18:37:35.944369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from imblearn.over_sampling import RandomOverSampler\n\n#ros = RandomOverSampler(sampling_strategy= 'not majority')#string\n#ros = RandomOverSampler(sampling_strategy= 1) #Numerical value\n\n#x_ros, y_ros= ros.fit_resample(X, y)\n\n#ax = y_ros.value_counts().plot.pie(autopct='%.2f')\n#_ = ax.set_title('over-sampling')","metadata":{"execution":{"iopub.status.busy":"2023-11-28T18:37:36.802306Z","iopub.execute_input":"2023-11-28T18:37:36.803189Z","iopub.status.idle":"2023-11-28T18:37:36.996426Z","shell.execute_reply.started":"2023-11-28T18:37:36.803151Z","shell.execute_reply":"2023-11-28T18:37:36.995114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## B- Split data into train, valid, test","metadata":{}},{"cell_type":"code","source":"#train, valid  and test dataframes\ntrain, testval = train_test_split(Df, test_size = 0.2, shuffle = True, random_state = 123)\nvalid, test = train_test_split(testval, test_size = 0.5, shuffle = True, random_state = 123)\n\nprint(\"Train shape: \", train.shape)\nprint(\"Valid shape: \", valid.shape)\nprint(\"Test shape: \",test.shape)\n\ntrain.Labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:46:55.029414Z","iopub.execute_input":"2023-11-28T20:46:55.029833Z","iopub.status.idle":"2023-11-28T20:46:55.045612Z","shell.execute_reply.started":"2023-11-28T20:46:55.0298Z","shell.execute_reply":"2023-11-28T20:46:55.044563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## C- Data Augmentation","metadata":{}},{"cell_type":"code","source":"batch_size = 20   # As smaller, As more data generated ....In views of data size \nimg_size = (224, 224) # standard value (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\n\n#Create generators\n\ntr_G = ImageDataGenerator(\n    zca_whitening=True,\n    rotation_range=30.,\n    fill_mode='nearest',\n    )\n\nV_G = ImageDataGenerator()\n\nt_G = ImageDataGenerator()\n\n#Generate Appropriate Data for fitting into model\n\nTrain = tr_G.flow_from_dataframe(train, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)\nValid = V_G.flow_from_dataframe(valid, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)\nTest = t_G.flow_from_dataframe(test, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = False, batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:46:57.414107Z","iopub.execute_input":"2023-11-28T20:46:57.414536Z","iopub.status.idle":"2023-11-28T20:46:58.832989Z","shell.execute_reply.started":"2023-11-28T20:46:57.414502Z","shell.execute_reply":"2023-11-28T20:46:58.83213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## D- Represent a sample","metadata":{}},{"cell_type":"code","source":"# Define labels and their indices as a dict\nL_index = Train.class_indices\nL_index\n\n# Store Labels in a list\nKeys = list(L_index.keys())\nKeys\n\n#Get a sample batch\nimgs, labels = next(Train)\n\n# Visualization\nplt.figure(figsize= (15, 15))\n\nfor i in range(8):\n    plt.subplot(3, 4, i +1)\n    im = imgs[i]/255\n    plt.imshow(im)\n    \n    #Labelling\n    index = np.argmax(labels[i])\n    label = Keys[index]\n    plt.title(label, color = 'purple')\n    plt.axis('off')\n    \nplt.tight_layout()    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:47:06.674724Z","iopub.execute_input":"2023-11-28T20:47:06.675617Z","iopub.status.idle":"2023-11-28T20:47:09.294746Z","shell.execute_reply.started":"2023-11-28T20:47:06.67558Z","shell.execute_reply":"2023-11-28T20:47:09.293762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 Modelling","metadata":{}},{"cell_type":"markdown","source":"## A- Create a model using transfer learning with EfficientNetB2\n","metadata":{}},{"cell_type":"markdown","source":"#### * NOTE \"experts advise you make the base model initially not trainable. Then train for some number of epochs\n#### then fine tune model by making base model trainable and run more epochs\n#### It was found to be WRONG!!!! \n#### Making the base model trainable from the outset leads to faster convegence and a lower validation loss\n#### for the same number of total epochs!\"\nas mentioned at: https://www.kaggle.com/code/devanshajmera/chair\n\n\n\n#### --> I will be using EfficientNetB3 model with weights from imagenet.\n##### And I will using include_top=False option since it allows me to add my own output layer.\n\n","metadata":{}},{"cell_type":"markdown","source":"\n\n","metadata":{}},{"cell_type":"code","source":"# Define number of classes \nn_classes = len(list(Train.class_indices.keys()))\nn_classes\n\nimg_shape=(img_size[0], img_size[1], 3)\nmodel_name='EfficientNetB3'\nbase_model= EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n\n# Note you are always told NOT to make the base model trainable initially- that is WRONG you get better results leaving it trainable\nbase_model.trainable=True\nx=base_model.output\nx=BatchNormalization(axis=-1, momentum=0.999, epsilon=0.001 )(x)\nx = Dense(1024, kernel_regularizer = regularizers.l2(l = 0.01),activity_regularizer=regularizers.l1(0.005),\n                bias_regularizer=regularizers.l1(0.005) ,activation='relu')(x)\nx=Dropout(rate=.2, seed=123)(x)\nx = Dense(512, kernel_regularizer = regularizers.l2(l = 0.01),activity_regularizer=regularizers.l1(0.005),\n                bias_regularizer=regularizers.l1(0.005) ,activation='relu')(x)\nx=Dropout(rate=.3, seed=123)(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.01),activity_regularizer=regularizers.l1(0.005),\n                bias_regularizer=regularizers.l1(0.005) ,activation='relu')(x)\nx=Dropout(rate=.4, seed=123)(x)\noutput=Dense(n_classes, activation='softmax')(x)\nmodel=Model(inputs=base_model.input, outputs=output)\nlr=.0001 # start with this learning rate\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-11-28T20:47:17.896861Z","iopub.execute_input":"2023-11-28T20:47:17.897621Z","iopub.status.idle":"2023-11-28T20:47:21.501856Z","shell.execute_reply.started":"2023-11-28T20:47:17.897576Z","shell.execute_reply":"2023-11-28T20:47:21.500698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='elu'))\nmodel.add(Dense(256, activation='elu'))\nmodel.add(Dense(128, activation = 'elu'))\nmodel.add(Dense(5, activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:47:24.947832Z","iopub.execute_input":"2023-11-28T20:47:24.948212Z","iopub.status.idle":"2023-11-28T20:47:26.407492Z","shell.execute_reply.started":"2023-11-28T20:47:24.948178Z","shell.execute_reply":"2023-11-28T20:47:26.406699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    Adamax(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['acc']\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:47:29.660372Z","iopub.execute_input":"2023-11-28T20:47:29.661228Z","iopub.status.idle":"2023-11-28T20:47:29.681741Z","shell.execute_reply.started":"2023-11-28T20:47:29.661193Z","shell.execute_reply":"2023-11-28T20:47:29.680974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:47:33.148922Z","iopub.execute_input":"2023-11-28T20:47:33.149305Z","iopub.status.idle":"2023-11-28T20:47:33.213158Z","shell.execute_reply.started":"2023-11-28T20:47:33.149272Z","shell.execute_reply":"2023-11-28T20:47:33.212299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## B- Visualize model layers","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png')","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:47:41.703326Z","iopub.execute_input":"2023-11-28T20:47:41.703983Z","iopub.status.idle":"2023-11-28T20:47:41.793615Z","shell.execute_reply.started":"2023-11-28T20:47:41.703947Z","shell.execute_reply":"2023-11-28T20:47:41.79266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## C- Training phase","metadata":{}},{"cell_type":"code","source":"epochs = 50\nhistory = model.fit(x= Train, epochs= epochs, verbose= 1, validation_data= Valid, validation_steps= None, shuffle= False)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:47:53.946252Z","iopub.execute_input":"2023-11-28T20:47:53.947191Z","iopub.status.idle":"2023-11-28T21:14:00.19996Z","shell.execute_reply.started":"2023-11-28T20:47:53.947153Z","shell.execute_reply":"2023-11-28T21:14:00.198939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## D- Evaluation ","metadata":{}},{"cell_type":"code","source":"# accuracy and loss of Train\n\ntr_acc = history.history['acc']\ntr_loss = history.history['loss']\n\n\n# accuracy and loss or Valid\\\n\nv_acc = history.history['val_acc']\nv_loss = history.history['val_loss']\n\n\n# highest value of v_acc by getting its index\n\nindex_acc = np.argmax(v_acc)\nhigh_Vacc = v_acc[index_acc]\n\n\n# lowest value of v_loss by getting index\n\nindex_loss = np.argmin(v_loss)\nlow_Vloss = v_loss[index_loss]\n\n\n# n. of epochs based on length of tr_acc values\n\nEpochs =[]\nfor i in range(len(tr_acc)):\n    Epochs.append (i+1)\n\n    \n# Define best epoch\n\nbest_acc = f'Best epoch ={str(index_acc +1)}'\nbest_loss = f'Best epoch ={str(index_loss+1)}'","metadata":{"execution":{"iopub.status.busy":"2023-11-28T19:25:36.621374Z","iopub.execute_input":"2023-11-28T19:25:36.622103Z","iopub.status.idle":"2023-11-28T19:25:36.629234Z","shell.execute_reply.started":"2023-11-28T19:25:36.622069Z","shell.execute_reply":"2023-11-28T19:25:36.628072Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## E- Let's Visualize it","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\nplt.style.use('fivethirtyeight')\n\n\nplt.subplot(1,2,1)\nplt.plot(Epochs, tr_acc, \"g\", label = \"Train Accuarcy\")\nplt.plot(Epochs, v_acc, \"r\", label = \"Valid Accuarcy\")\nplt.scatter(index_acc+1, high_Vacc, s= 150, color = 'purple', label = best_acc)\n\nplt.title(\"Accuracy: Train Vs valid\")\nplt. xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n\nplt.subplot(1,2,2)\nplt.plot(Epochs, tr_loss, \"g\", label = \"Train Loss\")\nplt.plot(Epochs, v_loss, \"r\", label = \"Valid Loss\")\nplt.scatter(index_loss+1, low_Vloss, s= 150, color = 'purple', label = best_loss)\n\nplt.title(\"Loss: Train Vs valid\")\nplt. xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:14:55.45417Z","iopub.execute_input":"2023-11-28T21:14:55.45494Z","iopub.status.idle":"2023-11-28T21:14:56.354719Z","shell.execute_reply.started":"2023-11-28T21:14:55.454901Z","shell.execute_reply":"2023-11-28T21:14:56.353784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Vars\nTrain_sc = model.evaluate(Train, verbose = 1)\nValid_sc = model.evaluate(Valid, verbose = 1)\nTest_sc =model.evaluate(Test, verbose = 1)\n\n#Print\nprint('Train Scores : \\n    accuracy:', Train_sc[1], '\\n      Loss: ', Train_sc[0], '\\n________________________')\nprint('Valid Scores : \\n    accuracy:', Valid_sc[1], '\\n      Loss: ', Valid_sc[0], '\\n________________________')\nprint('Test Scores : \\n    accuracy:', Test_sc[1], '\\n      Loss: ', Test_sc[0], '\\n________________________')","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:15:46.801115Z","iopub.execute_input":"2023-11-28T21:15:46.801501Z","iopub.status.idle":"2023-11-28T21:16:17.236147Z","shell.execute_reply.started":"2023-11-28T21:15:46.801468Z","shell.execute_reply":"2023-11-28T21:16:17.235218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 Get  predictions","metadata":{}},{"cell_type":"code","source":"predictions = model.predict_generator(Test)\ny_pred = np.argmax(predictions, axis = 1)\n\n#Chack\nprint(predictions)\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:16:20.741539Z","iopub.execute_input":"2023-11-28T21:16:20.741835Z","iopub.status.idle":"2023-11-28T21:16:21.8341Z","shell.execute_reply.started":"2023-11-28T21:16:20.741807Z","shell.execute_reply":"2023-11-28T21:16:21.833084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use n. of keys of  Class indices to greate confusion matrix\nTest_cl_ind = Test.class_indices\n \n# Get Keys\nclasses = list(Test_cl_ind.keys())\n\n#CM\ncm = confusion_matrix(Test.classes, y_pred)\ncm","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:16:28.858884Z","iopub.execute_input":"2023-11-28T21:16:28.8596Z","iopub.status.idle":"2023-11-28T21:16:28.869278Z","shell.execute_reply.started":"2023-11-28T21:16:28.859561Z","shell.execute_reply":"2023-11-28T21:16:28.868342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualise it\nplt.figure(figsize =(8, 8))\nplt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Greens)\nplt.title(\"Confusion Matrix\")\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes,rotation = 45)\nplt.yticks(tick_marks, classes)\n\nthresh = cm.max()/2\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(i, j, cm[i, j], horizontalalignment = 'center', color = 'white' if cm[i,j] > thresh  else 'red')\n    \nplt.tight_layout()\nplt.xlabel('Predictions')\nplt.ylabel('Real Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:16:39.919848Z","iopub.execute_input":"2023-11-28T21:16:39.920561Z","iopub.status.idle":"2023-11-28T21:16:40.330231Z","shell.execute_reply.started":"2023-11-28T21:16:39.920522Z","shell.execute_reply":"2023-11-28T21:16:40.329192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calssification Report\nprint(classification_report(Test.classes, y_pred, target_names = classes))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:16:56.649604Z","iopub.execute_input":"2023-11-28T21:16:56.650594Z","iopub.status.idle":"2023-11-28T21:16:56.665027Z","shell.execute_reply.started":"2023-11-28T21:16:56.650555Z","shell.execute_reply":"2023-11-28T21:16:56.664048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7 Save model","metadata":{}},{"cell_type":"code","source":"model.save('effB3 CNN DR.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:17:06.118419Z","iopub.execute_input":"2023-11-28T21:17:06.119275Z","iopub.status.idle":"2023-11-28T21:17:07.430323Z","shell.execute_reply.started":"2023-11-28T21:17:06.119238Z","shell.execute_reply":"2023-11-28T21:17:07.429313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### If you found it useful...please upvote it!\n\n#### Thank you","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}